{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hate Speech Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: (31962, 3) 31962\n",
      "          id  label                                              tweet\n",
      "0          1      0   @user when a father is dysfunctional and is s...\n",
      "1          2      0  @user @user thanks for #lyft credit i can't us...\n",
      "2          3      0                                bihday your majesty\n",
      "3          4      0  #model   i love u take with u all the time in ...\n",
      "4          5      0             factsguide: society now    #motivation\n",
      "...      ...    ...                                                ...\n",
      "31957  31958      0  ate @user isz that youuu?ðððððð...\n",
      "31958  31959      0    to see nina turner on the airwaves trying to...\n",
      "31959  31960      0  listening to sad songs on a monday morning otw...\n",
      "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...\n",
      "31961  31962      0                   thank you @user for you follow  \n",
      "\n",
      "[31962 rows x 3 columns]\n",
      "Testing Set: (17197, 2) 17197\n",
      "          id                                              tweet\n",
      "0      31963  #studiolife #aislife #requires #passion #dedic...\n",
      "1      31964   @user #white #supremacists want everyone to s...\n",
      "2      31965  safe ways to heal your #acne!!    #altwaystohe...\n",
      "3      31966  is the hp and the cursed child book up for res...\n",
      "4      31967    3rd #bihday to my amazing, hilarious #nephew...\n",
      "...      ...                                                ...\n",
      "17192  49155  thought factory: left-right polarisation! #tru...\n",
      "17193  49156  feeling like a mermaid ð #hairflip #neverre...\n",
      "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...\n",
      "17195  49158  happy, at work conference: right mindset leads...\n",
      "17196  49159  my   song \"so glad\" free download!  #shoegaze ...\n",
      "\n",
      "[17197 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "print(\"Training Set:\" % train.columns,train.shape,len(train))\n",
    "print(train)\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "print(\"Testing Set:\" % test.columns,test.shape,len(test))\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "import re\n",
    "\n",
    "\n",
    "#Check for duplicate and empty data\n",
    "train.duplicated().sum\n",
    "train.isnull().sum()\n",
    "\n",
    "#Text Data Handling\n",
    "def clean_data(data, text_field):\n",
    "    data[text_field] = data[text_field].str.lower() #Convert all data into lowercase\n",
    "    data[text_field] = train[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))\n",
    "    return data\n",
    "\n",
    "training_data = clean_data(train,\"tweet\")\n",
    "testing_data = clean_data(test,\"tweet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling data imbalance --> Replicating the number of hate comments using upsampling method\n",
    "from sklearn.utils import resample\n",
    "# Split data and upsamble to one with the label 0 since it has less data\n",
    "train_label_1 = training_data[training_data.label == 1]  \n",
    "train_label_0 = training_data[training_data.label == 0]\n",
    "\n",
    "# Upsample the minority class (label 1) to match the majority class (label 0\n",
    "resampled_label_1 = resample(train_label_1,\n",
    "                             replace=True,\n",
    "                             n_samples=len(train_label_0),\n",
    "                             random_state=123)\n",
    "training_data_upsampled = pd.concat([resampled_label_1,train_label_0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a data pipline to get data from user and make prediction\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle\n",
    "\n",
    "\n",
    "x = np.array(training_data_upsampled[\"tweet\"])\n",
    "y = np.array(training_data_upsampled[\"label\"])\n",
    "\n",
    "cv = TfidfVectorizer()\n",
    "X = cv.fit_transform(x) #Convert words and letters into matrices\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)\n",
    "\n",
    "with open('decision_tree_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open('vectorizer','wb') as f:\n",
    "    pickle.dump(cv, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
